This project focuses on cleaning, preprocessing, and analyzing employee data using Python libraries NumPy and Pandas.
The dataset contains missing values and duplicate records, which are handled to improve data quality and reliability before performing basic statistical analysis.

ğŸ¯ Objective

To transform a raw employee dataset into a clean and structured format by:

Handling missing values
Removing duplicate records
Performing descriptive analysis
Extracting useful business insights
ğŸ› ï¸ Technologies Used

Python
â€¢ Pandas â€“ data manipulation and analysis
â€¢ NumPy â€“ numerical operations
â€¢ Excel (.xlsx) â€“ input and output format

ğŸ”„ Data Cleaning Steps Performed

1ï¸âƒ£ Handling Missing Values

Replaced missing Name, City, Department, and Performance values with "Unknown".
Filled missing Age values using the mean age.
Filled missing Salary values using the average salary.
2ï¸âƒ£ Removing Duplicates

Duplicate employee records were identified and removed to ensure data consistency.
ğŸ“ˆ Data Analysis & Insights

âœ” Salary Statistics
Calculated average, minimum, and maximum salary of employees.

âœ” Department-Wise Analysis
Counted number of employees per department.

Computed average salary per department.
âœ” Location-Wise Analysis

Counted employees based on city.
âœ” Top Earners

Identified the top 5 highest-paid employees in the organization.

ğŸ’¾ Output
The cleaned and processed dataset is exported as clean_data.xlsx for further use or reporting.

âœ… Key Outcomes
âœ” Advantages

â€¢ Improved data quality and accuracy
â€¢ Demonstrates real-world data cleaning skills
â€¢ Useful for HR analytics and reporting
â€¢ Beginner-friendly but practical project

âŒ Limitations

â€¢ No visualization included
â€¢ Outlier treatment not implemented

ğŸ”® Future Enhancements

â€¢ Add Exploratory Data Analysis (EDA) with charts
â€¢ Implement outlier detection
â€¢ Add data validation rules
â€¢ Integrate visualization using Matplotlib / Seaborn
